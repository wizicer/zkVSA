---
import Layout from "../layouts/Layout.astro";
import WorkflowSVG from "../assets/workflow.svg";
import IntroSVG from "../assets/intro.svg";
import VerifyButton from "../components/VerifyButton.astro";
import Step from "../components/Step.astro";
import LatexRenderer from "../components/LatexRenderer.astro";
import samplesData from "../data/samples.json";
import type { Sample } from "../data/types.ts";
import InfoIcon from "../icons/SolarInfoSquareOutline.astro";

// Type the imported JSON data
const samples: Sample[] = samplesData as Sample[];

// Verifier state
let isVerifierLoaded = false;

const selectiveAlgorithms = ["f32", "m377"] as const;
const semitones = ["3", "2", "1", "-1", "-2", "-3"] as const;
const algorithmNames = {
  f32: { name: "FPP", description: "Floating-point PV-TSM" },
  m377: { name: "ZK-VSA", description: "Proposed SNARK-friendly PV-TSM" },
};
---

<Layout>
  <main class="min-h-screen bg-white">
    <!-- Title and Authors Section -->
    <section class="py-12">
      <div class="max-w-4xl mx-auto px-6 text-center">
        <h1 class="text-2xl font-bold text-gray-900 mb-6">
          ZK-VSA: ZERO-KNOWLEDGE VERIFIABLE SPEAKER ANONYMIZATION LEVERAGING PHASE VOCODER WITH TIME-SCALE MODIFICATION
        </h1>
        <div class="mt-4 text-base text-gray-800">
          <div class="italic text-lg">
            Shuang Liang<sup>1</sup>, Yang Hua<sup>2</sup>, Peishen Yan<sup>1</sup>, Linshan Jiang<sup>3</sup>, Tao Song<sup
              >1,*</sup
            >, Bin Yao<sup>1,*</sup>, Haibing Guan<sup>1</sup>
          </div>
          <div class="mt-4 text-sm text-gray-700">
            <div><sup>1</sup> School of Computer Science, Shanghai Jiao Tong University, Shanghai, China</div>
            <div>
              <sup>2</sup> School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, Belfast,
              United Kingdom
            </div>
            <div><sup>3</sup> Institute of Data Science, National University of Singapore, Singapore, Singapore</div>
          </div>
          <!-- <div class="mt-2 text-sm text-gray-600 italic">
            * Corresponding author: Tao Song (<a href="mailto:songt333@sjtu.edu.cn">songt333@sjtu.edu.cn</a>), Bin Yao (<a href="mailto:yaobin@cs.sjtu.edu.cn">yaobin@cs.sjtu.edu.cn</a>)
          </div> -->
        </div>
      </div>
    </section>

    <!-- Abstract Section -->
    <section class="py-8">
      <div class="max-w-4xl mx-auto px-6">
        <h2 class="text-2xl font-semibold text-gray-800 mb-4">Abstract</h2>
        <p class="text-gray-700 leading-relaxed text-justify">
          Speaker anonymization protects against speaker identity inference, yet third parties cannot verify that released speech
          is authenticated and anonymized as predefined without revealing the original. We propose <em
            >Verifiable Speaker Anonymization (VSA)</em
          >, a paradigm that enables public verification that a predefined anonymization has been applied while the original
          remains hidden. We instantiate this paradigm as <em>ZK-VSA</em> using zero-knowledge succinct non-interactive arguments of
          knowledge (ZK-SNARKs): we encode phase vocoder with time-scale modification (PV-TSM) as arithmetic constraints suitable for
          succinct proofs, complemented by SNARK-friendly phase handling, and integrate cryptographic commitments with digital signatures
          for authentication. We evaluate ZK-VSA on LibriSpeech, using automatic speech recognition (ASR) for intelligibility and automatic
          speaker verification (ASV) for anonymity. Our proof-constrained anonymization closely matches floating-point PV-TSM, while
          proofs add only a slight overhead and verify in milliseconds. These results demonstrate the practicality of VSA and open
          a path to proof-based guarantees for broader speech transformations.
        </p>
        <figure class="flex flex-col items-center my-8">
          <div class="w-full flex justify-center">
            <IntroSVG class="max-w-2xl w-full h-auto" />
          </div>
          <figcaption class="mt-4 text-center text-sm text-gray-600 max-w-2xl">
            Fig.1: Scenario of <em>verifiable speaker anonymization</em> (VSA). A trusted device records and signs speech signal; the
            system outputs an anonymized signal and proof for verification, resisting: (a) <em>inversion attacks</em>—recovering
            the original signal, and (b) <em>re-identification attacks</em>—inferring the speaker's identity.
          </figcaption>
        </figure>
      </div>
    </section>

    <!-- System Model Section -->
    <section class="py-8">
      <div class="max-w-4xl mx-auto px-6">
        <h2 class="text-2xl font-semibold text-gray-800 mb-6">System Workflow</h2>
        <figure class="flex flex-col items-center">
          <div class="flex justify-center w-full">
            <WorkflowSVG class="max-w-lg w-full h-auto" />
          </div>
          <figcaption class="mt-4 text-center text-sm text-gray-600 max-w-2xl">
            <strong>Fig.2:</strong> End-to-end workflow from trusted capture to verifiable anonymized release: device-signed STFT commitments,
            PV-TSM on phase, a proof bound to those commitments, and public verification with ISTFT reconstruction.
          </figcaption>
        </figure>
        <p class="text-gray-700 leading-relaxed text-justify mt-4">
          As illustrated in the Fig.2, before recording, a <em>trusted device</em>
          <Step number={1} /> generates a keypair <LatexRenderer expression="(\\mathsf{sk},\\mathsf{pk})" />. It then records the
          input signal <LatexRenderer expression="x" />, <Step number={2} /> computes the STFT to obtain magnitude <LatexRenderer
            expression="R"
          /> and phase <LatexRenderer expression="\\Phi_X" />, and derives digests <LatexRenderer expression="h_R=H(R)" /> and <LatexRenderer
            expression="h_{\\Phi_X}=H(\\Phi_X)"
          />. The device <Step number={3} /> signs these digests to produce <LatexRenderer
            expression="\\sigma_R=\\mathrm{Sign}_{\\mathsf{sk}}(h_R)"
          /> and <LatexRenderer expression="\\sigma_{\\Phi_X}=\\mathrm{Sign}_{\\mathsf{sk}}(h_{\\Phi_X})" />, which serve as
          commitments binding later computations to the original capture without revealing <LatexRenderer expression="x" />.
        </p>
        <p class="text-gray-700 leading-relaxed text-justify">
          <span class="mx-4"></span>A <em>prover</em> (not necessarily the recording device) <Step number={4} /> applies the anonymization
          operator to obtain <LatexRenderer expression="\\Phi_Y=\\mathrm{PV\\text{-}TSM}(\\Phi_X)" /> while leaving <LatexRenderer
            expression="R"
          /> unchanged, and <Step number={5} /> generates a succinct proof <LatexRenderer expression="\\pi" /> attesting both the PV-TSM
          relation and the validity of the signature on <LatexRenderer expression="h_{\\Phi_X}" />, while also binding <LatexRenderer
            expression="\\Phi_Y"
          /> to <LatexRenderer expression="h_{\\Phi_Y}=H(\\Phi_Y)" />. The prover <Step number={6} /> releases <LatexRenderer
            expression="R"
          /> as-is.
        </p>
        <p class="text-gray-700 leading-relaxed text-justify">
          <span class="mx-4"></span>Verification uses only public values <LatexRenderer
            expression="(\\mathsf{pk},\\sigma_R,h_{\\Phi_X},h_{\\Phi_Y},\\pi)"
          /> with <LatexRenderer expression="(R,\\Phi_Y)" />. The <em>verifier</em>
          <Step number={7} /> checks <LatexRenderer expression="\\sigma_R" /> under <LatexRenderer expression="\\mathsf{pk}" /> and
          verifies that <LatexRenderer expression="\\pi" /> attests the transformation from <LatexRenderer expression="\\Phi_X" />
          to <LatexRenderer expression="\\Phi_Y" /> with commitments <LatexRenderer expression="h_{\\Phi_X}" /> and <LatexRenderer
            expression="h_{\\Phi_Y}"
          />. Finally, it <Step number={8} /> runs ISTFT on <LatexRenderer expression="(R,\\Phi_Y)" /> to reconstruct the released
          signal <LatexRenderer expression="y" /> without accessing <LatexRenderer expression="x" />.
        </p>
      </div>
    </section>

    <!-- Samples Section -->
    <section class="py-8">
      <div class="max-w-7xl mx-auto px-6">
        <h2 class="text-2xl font-semibold text-gray-800 mb-6">Samples</h2>
        <div class="overflow-x-auto">
          <table class="w-full border-collapse">
            <thead>
              <tr class="bg-gray-100 border-b border-gray-300">
                <th rowspan="2" class="px-4 py-3 text-left font-semibold text-gray-800">Transcript</th>
                <th rowspan="2" class="px-4 py-3 text-center font-semibold text-gray-800">Original Utterance</th>
                <th rowspan="2" class="px-4 py-3 text-center font-semibold text-gray-800">Semitone</th>
                <th colspan={selectiveAlgorithms.length} class="px-4 py-3 text-center font-semibold text-gray-800"
                  >Anonymized Utterance</th
                >
                <th rowspan="2" class="px-4 py-3 text-center font-semibold text-gray-800">
                  <div class="flex flex-col items-center space-y-2">
                    <span>Proof (ZK-VSA)</span>
                    <button
                      id="load-verifier-btn"
                      class="px-3 py-1 bg-orange-600 text-white text-xs rounded hover:bg-orange-700 transition-colors"
                    >
                      Load Verifier
                    </button>
                  </div>
                </th>
              </tr>
              <tr class="bg-gray-100 border-b border-gray-300">
                {
                  selectiveAlgorithms.map((algorithm) => (
                    <th class="px-2 py-2 text-center font-medium text-gray-700">
                      <span class="inline-flex items-center">
                        {algorithmNames[algorithm as keyof typeof algorithmNames].name}
                        <span class="ml-1 group relative cursor-pointer align-middle">
                          <InfoIcon class="h-4 w-4 text-gray-400 hover:text-gray-600" />
                          <span class="absolute left-1/2 -translate-x-1/2 mt-2 w-48 rounded bg-gray-800 text-white text-xs px-3 py-2 opacity-0 group-hover:opacity-100 transition-opacity pointer-events-none z-10 whitespace-normal">
                            {algorithmNames[algorithm as keyof typeof algorithmNames].description}
                          </span>
                        </span>
                      </span>
                    </th>
                  ))
                }
              </tr>
            </thead>
            <tbody>
              {
                samples.map((sample: Sample, sampleIndex: number) =>
                  semitones.map((semitone, semitoneIndex: number) => (
                    <tr class="hover:bg-gray-50 border-b border-gray-200">
                      {semitoneIndex === 0 && (
                        <td rowspan="6" class="px-4 py-3 text-sm text-gray-700 max-w-xs">
                          {sample.transcript}
                        </td>
                      )}
                      {semitoneIndex === 0 && (
                        <td rowspan="6" class="px-4 py-3 text-center">
                          <audio controls class="w-24 h-6">
                            <source src={`/audio/${sample.name}.wav`} type="audio/wav" />
                            Your browser does not support the audio element.
                          </audio>
                        </td>
                      )}
                      <td class="px-4 py-3 text-center font-medium text-gray-800">{semitone}</td>
                      {selectiveAlgorithms.map((algorithm) => (
                        <td class="px-2 py-3 text-center">
                          <audio controls class="w-24 h-6">
                            <source src={`/audio/${sample.name}_${algorithm}_${semitone}.flac`} type="audio/flac" />
                            Your browser does not support the audio element.
                          </audio>
                        </td>
                      ))}
                      <td class="px-4 py-3 text-center">
                        <VerifyButton
                          proofId={`${sample.name}_${semitone}_m377`}
                          downloadUrl={`/proofs/${sample.name}_${semitone}_m377.json`}
                          fileSize="292 bytes"
                          disabled={!isVerifierLoaded}
                        />
                      </td>
                    </tr>
                  ))
                )
              }
            </tbody>
          </table>
        </div>
      </div>
    </section>
  </main>
</Layout>

<style>
  /* Audio control styles as specified in appendix */
  audio {
    width: 100px;
    height: 20px;
  }
</style>

<script>
  import { showNotification } from "../utils/notifications.ts";

  // Import type declarations
  import "../types/wasm.d.ts";

  // Global verifier state
  let isVerifierLoaded = false;
  let wasmModule = null;

  // Load verifier function
  async function loadVerifier() {
    const loadBtn = document.getElementById("load-verifier-btn") as HTMLButtonElement;
    if (!loadBtn) return;

    // Show loading state
    loadBtn.textContent = "Loading...";
    loadBtn.disabled = true;
    loadBtn.classList.remove("bg-orange-600", "hover:bg-orange-700");
    loadBtn.classList.add("bg-orange-500");

    try {
      // Load the WASM module
      const go = new (window as any).Go();
      const base = import.meta.env.BASE_URL;
      const result = await WebAssembly.instantiateStreaming(fetch(base + "/wasm/main.wasm"), go.importObject);

      // Run the Go program
      go.run(result.instance);

      // Check if functions are available
      if (typeof window.verifyProof === "function") {
        // Mark verifier as loaded
        isVerifierLoaded = true;
        wasmModule = result.instance;

        // Update button state
        loadBtn.textContent = "✓ Verifier Loaded";
        loadBtn.classList.remove("bg-orange-500");
        loadBtn.classList.add("bg-green-600");

        // Enable all verify buttons
        const verifyButtons = document.querySelectorAll("[data-verify-button]") as NodeListOf<HTMLButtonElement>;
        verifyButtons.forEach((button) => {
          button.disabled = false;
          button.classList.remove("bg-gray-400", "cursor-not-allowed");
          button.classList.add("bg-blue-600", "hover:bg-blue-700");
          button.title = "";
        });

        // Show success notification
        showNotification("Verifier loaded successfully! You can now verify proofs.", "success");
      } else {
        throw new Error("Required functions not found in WASM module");
      }
    } catch (error) {
      console.error("Failed to load WASM module:", error);

      // Handle error
      loadBtn.textContent = "Load Verifier";
      loadBtn.disabled = false;
      loadBtn.classList.remove("bg-orange-500");
      loadBtn.classList.add("bg-orange-600", "hover:bg-orange-700");

      showNotification("Failed to load verifier. Please try again.", "error");
    }
  }

  // Initialize on page load
  document.addEventListener("DOMContentLoaded", () => {
    const loadBtn = document.getElementById("load-verifier-btn");
    if (loadBtn) {
      loadBtn.addEventListener("click", loadVerifier);
    }
  });
</script>

<script is:inline>
  const script = document.createElement("script");
  script.src = "/zkVSA/wasm/wasm_exec.js";
  script.async = true;
  document.head.appendChild(script);
</script>
